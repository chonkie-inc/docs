{
    "post": {
        "summary": "Token Chunker",
        "description": "Splits text into chunks based on token count, ensuring each chunk stays within specified token limits.",
        "operationId": "get_token_chunks_v1_chunk_token_post",
        "requestBody": {
            "required": true,
            "content": {
                "multipart/form-data": {
                    "schema": {
                        "type": "object",
                        "properties": {
                            "file": {
                                "type": "string",
                                "format": "binary",
                                "description": "The file to chunk."
                            },
                            "tokenizer": {
                                "type": "string",
                                "title": "Tokenizer",
                                "default": "gpt2",
                                "description": "Tokenizer to use. Can be a string identifier or a tokenizer instance."
                            },
                            "chunk_size": {
                                "type": "integer",
                                "title": "Chunk Size",
                                "default": 512,
                                "description": "Maximum number of tokens per chunk."
                            },
                            "chunk_overlap": {
                                "type": "integer",
                                "title": "Chunk Overlap",
                                "default": 0,
                                "description": "Number or percentage of overlapping tokens between chunks."
                            },
                            "return_type": {
                                "type": "string",
                                "title": "Return Type",
                                "default": "chunks",
                                "enum": [ "texts", "chunks" ],
                                "description": "Whether to return chunks as `Chunk` objects or plain text strings."
                            }
                        }
                    }
                }
            }
        },
        "responses": {
            "200": {
                "description": "Successful Response: A list of `Chunk` objects.",
                "content": {
                    "application/json": {
                        "schema": {
                            "title": "TokenChunkResponse",
                            "type": "array",
                            "items": {
                                "$ref": "../schemas.json#/schemas/Chunk"
                            },
                            "description": "A list containing `Chunk` objects, each detailing a segment of the original text based on token count."
                        }
                    }
                }
            }
        }
    }
}
