{
    "schemas": {
        "Chunk": {
            "title": "Chunk",
            "description": "Base representation of a text chunk with core metadata.",
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "title": "Text",
                    "description": "The actual text content of the chunk."
                },
                "start_index": {
                    "type": "integer",
                    "title": "Start Index",
                    "description": "The starting character index of the chunk within the original input text."
                },
                "end_index": {
                    "type": "integer",
                    "title": "End Index",
                    "description": "The ending character index (exclusive) of the chunk within the original input text."
                },
                "token_count": {
                    "type": "integer",
                    "title": "Token Count",
                    "description": "The number of tokens in this specific chunk, according to the tokenizer used."
                }
            }
        },
        "SentenceSchema": {
            "title": "Sentence",
            "description": "Represents a single sentence with metadata, used within sentence-based chunks.",
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "title": "Text",
                    "description": "The actual text content of the sentence."
                },
                "start_index": {
                    "type": "integer",
                    "title": "Start Index",
                    "description": "The starting character index of the sentence within the original input text."
                },
                "end_index": {
                    "type": "integer",
                    "title": "End Index",
                    "description": "The ending character index (exclusive) of the sentence within the original input text."
                },
                "token_count": {
                    "type": "integer",
                    "title": "Token Count",
                    "description": "The number of tokens in this specific sentence, according to the tokenizer used."
                }
            }
        },
        "SemanticSentenceSchema": {
            "title": "SemanticSentence",
            "description": "Represents a single sentence within a semantic chunk, including an optional embedding vector.",
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "title": "Text",
                    "description": "The actual text content of the sentence."
                },
                "start_index": {
                    "type": "integer",
                    "title": "Start Index",
                    "description": "The starting character index of the sentence within the original input text."
                },
                "end_index": {
                    "type": "integer",
                    "title": "End Index",
                    "description": "The ending character index (exclusive) of the sentence within the original input text."
                },
                "token_count": {
                    "type": "integer",
                    "title": "Token Count",
                    "description": "The number of tokens in this specific sentence, according to the tokenizer used."
                },
                "embedding": {
                    "type": [
                        "array",
                        "null"
                    ],
                    "items": {
                        "type": "number",
                        "format": "float"
                    },
                    "title": "Embedding",
                    "description": "Optional embedding vector (list of floats) for the sentence."
                }
            }
        },
        "SentenceChunkSchema": {
            "title": "SentenceChunk",
            "description": "Represents a chunk of text composed of one or more `Sentence` objects.",
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "title": "Text",
                    "description": "The actual text content of the chunk."
                },
                "start_index": {
                    "type": "integer",
                    "title": "Start Index",
                    "description": "The starting character index of the chunk within the original input text."
                },
                "end_index": {
                    "type": "integer",
                    "title": "End Index",
                    "description": "The ending character index (exclusive) of the chunk within the original input text."
                },
                "token_count": {
                    "type": "integer",
                    "title": "Token Count",
                    "description": "The number of tokens in this specific chunk, according to the tokenizer used."
                },
                "sentences": {
                    "type": "array",
                    "items": {
                        "$ref": "#/schemas/SentenceSchema"
                    },
                    "title": "Sentences",
                    "description": "List of `Sentence` objects contained within this chunk."
                }
            }
        },
        "RecursiveChunkSchema": {
            "title": "RecursiveChunk",
            "description": "Represents a chunk generated by the Recursive Chunker, including its level in the recursive hierarchy.",
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "title": "Text",
                    "description": "The actual text content of the chunk."
                },
                "start_index": {
                    "type": "integer",
                    "title": "Start Index",
                    "description": "The starting character index of the chunk within the original input text."
                },
                "end_index": {
                    "type": "integer",
                    "title": "End Index",
                    "description": "The ending character index (exclusive) of the chunk within the original input text."
                },
                "token_count": {
                    "type": "integer",
                    "title": "Token Count",
                    "description": "The number of tokens in this specific chunk, according to the tokenizer used."
                },
                "level": {
                    "type": "integer",
                    "title": "Level",
                    "description": "The level of this chunk in the recursive splitting process (starts from 0)."
                }
            }
        },
        "SemanticChunkSchema": {
            "title": "SemanticChunk",
            "description": "Represents a chunk generated by semantic chunking methods (Semantic, SDPM), containing `SemanticSentence` objects potentially with embeddings.",
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "title": "Text",
                    "description": "The actual text content of the chunk."
                },
                "start_index": {
                    "type": "integer",
                    "title": "Start Index",
                    "description": "The starting character index of the chunk within the original input text."
                },
                "end_index": {
                    "type": "integer",
                    "title": "End Index",
                    "description": "The ending character index (exclusive) of the chunk within the original input text."
                },
                "token_count": {
                    "type": "integer",
                    "title": "Token Count",
                    "description": "The number of tokens in this specific chunk, according to the tokenizer used."
                },
                "sentences": {
                    "type": "array",
                    "items": {
                        "$ref": "#/schemas/SemanticSentenceSchema"
                    },
                    "title": "Sentences",
                    "description": "List of `SemanticSentence` objects contained within this chunk."
                }
            }
        },
        "LateChunkSchema": {
            "title": "LateChunk",
            "description": "Represents a chunk generated by the Late Chunker, containing standard sentences and an optional chunk-level embedding derived from the full document.",
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "title": "Text",
                    "description": "The actual text content of the chunk."
                },
                "start_index": {
                    "type": "integer",
                    "title": "Start Index",
                    "description": "The starting character index of the chunk within the original input text."
                },
                "end_index": {
                    "type": "integer",
                    "title": "End Index",
                    "description": "The ending character index (exclusive) of the chunk within the original input text."
                },
                "token_count": {
                    "type": "integer",
                    "title": "Token Count",
                    "description": "The number of tokens in this specific chunk, according to the tokenizer used."
                },
                "sentences": {
                    "type": "array",
                    "items": {
                        "$ref": "#/schemas/SentenceSchema"
                    },
                    "title": "Sentences",
                    "description": "List of standard `Sentence` objects contained within this chunk."
                },
                "embedding": {
                    "type": [
                        "array",
                        "null"
                    ],
                    "items": {
                        "type": "number",
                        "format": "float"
                    },
                    "title": "Embedding",
                    "description": "Optional embedding vector (list of floats) for the entire chunk, derived from the full document embedding."
                }
            }
        },
        "NodeSchema": {
            "title": "Node",
            "description": "Represents a node in the Abstract Syntax Tree (AST) of the code, used by CodeChunker.",
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "title": "Text",
                    "description": "The text content of the node."
                },
                "start_byte": {
                    "type": "integer",
                    "title": "Start Byte",
                    "description": "The starting byte index of the node within the original code text."
                },
                "end_byte": {
                    "type": "integer",
                    "title": "End Byte",
                    "description": "The ending byte index (exclusive) of the node within the original code text."
                },
                "type": {
                    "type": "string",
                    "title": "Type",
                    "description": "The type of the AST node (e.g., 'function_definition', 'identifier')."
                }
            }
        },
        "CodeChunkSchema": {
            "title": "CodeChunk",
            "description": "Represents a chunk generated by the Code Chunker, containing a code snippet and optionally corresponding AST nodes.",
            "type": "object",
            "properties": {
                "text": {
                    "type": "string",
                    "title": "Text",
                    "description": "The actual code text content of the chunk."
                },
                "start_index": {
                    "type": "integer",
                    "title": "Start Index",
                    "description": "The starting character index of the chunk within the original input code."
                },
                "end_index": {
                    "type": "integer",
                    "title": "End Index",
                    "description": "The ending character index (exclusive) of the chunk within the original input code."
                },
                "token_count": {
                    "type": "integer",
                    "title": "Token Count",
                    "description": "The number of tokens in this specific chunk, according to the tokenizer used."
                },
                "nodes": {
                    "type": [
                        "array",
                        "null"
                    ],
                    "items": {
                        "$ref": "#/schemas/NodeSchema"
                    },
                    "title": "Nodes",
                    "description": "Optional list of AST `Node` objects corresponding to this code chunk (present if `include_nodes` is true)."
                }
            }
        },
        "ErrorRES": {
            "properties": {
                "message": {
                    "type": "string",
                    "title": "Message"
                },
                "status": {
                    "type": "integer",
                    "title": "Status",
                    "default": 500
                }
            },
            "type": "object",
            "title": "ErrorRES",
            "description": "Error response for the Chonkie API."
        },
        "HTTPValidationError": {
            "properties": {
                "detail": {
                    "items": {
                        "$ref": "#/schemas/ValidationError"
                    },
                    "type": "array",
                    "title": "Detail"
                }
            },
            "type": "object",
            "title": "HTTPValidationError"
        },
        "LateChunkerREQ": {
            "title": "LateChunkerREQ",
            "description": "Data to pass to the Late Chunker.",
            "type": "object",
            "required": [
                "text"
            ],
            "properties": {
                "text": {
                    "anyOf": [
                        {
                            "type": "string"
                        },
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        }
                    ],
                    "title": "Text",
                    "description": "The input text or list of texts to be chunked."
                },
                "embedding_model": {
                    "type": "string",
                    "title": "Embedding Model",
                    "default": "sentence-transformers/all-minilm-l6-v2",
                    "description": "SentenceTransformer model identifier to use for embedding."
                },
                "chunk_size": {
                    "type": "integer",
                    "title": "Chunk Size",
                    "default": 512,
                    "description": "Maximum number of tokens per chunk."
                },
                "recipe": {
                    "type": "string",
                    "title": "Recipe",
                    "default": "default",
                    "description": "Pre-defined recursive rules for splitting. Find all recipes on our [Hugging Face Hub](https://huggingface.co/datasets/chonkie-ai/recipes)."
                },
                "lang": {
                    "type": "string",
                    "title": "Language",
                    "default": "en",
                    "description": "Language of the text, used with recipes. Must match the language of the recipe."
                },
                "min_characters_per_chunk": {
                    "type": "integer",
                    "title": "Min Characters Per Sentence",
                    "default": 24,
                    "description": "Minimum number of characters per sentence."
                }
            },
            "additionalProperties": false
        },
        "RecursiveChunkerREQ": {
            "title": "RecursiveChunkerREQ",
            "description": "Data to pass to the Recursive Character Text Splitter.",
            "type": "object",
            "required": [
                "text"
            ],
            "properties": {
                "text": {
                    "anyOf": [
                        {
                            "type": "string"
                        },
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        }
                    ],
                    "title": "Text",
                    "description": "The input text or list of texts to be chunked."
                },
                "tokenizer_or_token_counter": {
                    "type": "string",
                    "title": "Tokenizer Or Token Counter",
                    "default": "gpt2",
                    "description": "Tokenizer or token counting function to use. Can be a string identifier or an instance."
                },
                "chunk_size": {
                    "type": "integer",
                    "title": "Chunk Size",
                    "default": 512,
                    "description": "Maximum number of tokens per chunk."
                },
                "recipe": {
                    "type": "string",
                    "title": "Recipe",
                    "default": "default",
                    "description": "Pre-defined rules for chunking. Find all recipes on our [Hugging Face Hub](https://huggingface.co/datasets/chonkie-ai/recipes)."
                },
                "lang": {
                    "type": "string",
                    "title": "Language",
                    "default": "en",
                    "description": "Language of the text, used with recipes. Must match the language of the recipe."
                },
                "min_characters_per_chunk": {
                    "type": "integer",
                    "title": "Min Characters Per Chunk",
                    "default": 1,
                    "description": "Minimum number of characters per chunk."
                },
                "return_type": {
                    "type": "string",
                    "title": "Return Type",
                    "default": "chunks",
                    "enum": [
                        "texts",
                        "chunks"
                    ],
                    "description": "Whether to return chunks as text strings or as `RecursiveChunk` objects."
                }
            },
            "additionalProperties": false
        },
        "SDPMChunkerREQ": {
            "title": "SDPMChunkerREQ",
            "description": "Data to pass to the SDPM Chunker.",
            "type": "object",
            "required": [
                "text"
            ],
            "properties": {
                "text": {
                    "anyOf": [
                        {
                            "type": "string"
                        },
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        }
                    ],
                    "title": "Text",
                    "description": "The input text or list of texts to be chunked."
                },
                "embedding_model": {
                    "type": "string",
                    "title": "Embedding Model",
                    "default": "minishlab/potion-base-8M",
                    "description": "Model identifier or embedding model instance to use for semantic analysis."
                },
                "threshold": {
                    "anyOf": [
                        {
                            "type": "string",
                            "const": "auto"
                        },
                        {
                            "type": "number"
                        },
                        {
                            "type": "integer"
                        }
                    ],
                    "title": "Threshold",
                    "default": "auto",
                    "description": "Similarity threshold for grouping sentences. Can be a float [0,1] for direct threshold, int (1,100] for percentile, or 'auto' for automatic calculation."
                },
                "mode": {
                    "type": "string",
                    "title": "Mode",
                    "default": "window",
                    "description": "Mode for grouping sentences, either 'cumulative' or 'window'."
                },
                "chunk_size": {
                    "type": "integer",
                    "title": "Chunk Size",
                    "default": 512,
                    "description": "Maximum tokens per chunk."
                },
                "similarity_window": {
                    "type": "integer",
                    "title": "Similarity Window",
                    "default": 1,
                    "description": "Number of preceding sentences to consider for similarity comparison."
                },
                "min_sentences": {
                    "type": "integer",
                    "title": "Min Sentences",
                    "default": 1,
                    "description": "Minimum number of sentences per chunk."
                },
                "min_characters_per_sentence": {
                    "type": "integer",
                    "title": "Min Characters Per Sentence",
                    "default": 12,
                    "description": "Minimum number of characters per sentence."
                },
                "threshold_step": {
                    "type": "number",
                    "title": "Threshold Step",
                    "default": 0.01,
                    "description": "Step size used when automatically calculating the similarity threshold."
                },
                "delim": {
                    "anyOf": [
                        {
                            "type": "string"
                        },
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        }
                    ],
                    "title": "Delim",
                    "default": [
                        ".",
                        "!",
                        "?",
                        "\n"
                    ],
                    "description": "Delimiters to split sentences on."
                },
                "skip_window": {
                    "type": "integer",
                    "title": "Skip Window",
                    "default": 1,
                    "description": "Number of chunks to skip when looking for similarities in the second pass."
                },
                "return_type": {
                    "type": "string",
                    "title": "Return Type",
                    "default": "chunks",
                    "enum": [
                        "texts",
                        "chunks"
                    ],
                    "description": "Return type for the chunking process. If 'chunks', returns a list of `SemanticChunk` objects. If 'texts', returns a list of strings."
                }
            },
            "additionalProperties": false
        },
        "SemanticChunkerREQ": {
            "title": "SemanticChunkerREQ",
            "description": "Data to pass to the Semantic Chunker.",
            "type": "object",
            "required": [
                "text"
            ],
            "properties": {
                "text": {
                    "anyOf": [
                        {
                            "type": "string"
                        },
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        }
                    ],
                    "title": "Text",
                    "description": "The input text or list of texts to be chunked."
                },
                "embedding_model": {
                    "type": "string",
                    "title": "Embedding Model",
                    "default": "minishlab/potion-base-8M",
                    "description": "Model identifier or embedding model instance to use for semantic analysis."
                },
                "threshold": {
                    "anyOf": [
                        {
                            "type": "string",
                            "const": "auto"
                        },
                        {
                            "type": "number"
                        },
                        {
                            "type": "integer"
                        }
                    ],
                    "title": "Threshold",
                    "default": "auto",
                    "description": "Similarity threshold for grouping sentences. Can be a float [0,1] for direct threshold, int (1,100] for percentile, or 'auto' for automatic calculation."
                },
                "chunk_size": {
                    "type": "integer",
                    "title": "Chunk Size",
                    "default": 512,
                    "description": "Maximum tokens per chunk."
                },
                "similarity_window": {
                    "type": "integer",
                    "title": "Similarity Window",
                    "default": 1,
                    "description": "Number of preceding sentences to consider for similarity comparison."
                },
                "min_sentences": {
                    "type": "integer",
                    "title": "Min Sentences",
                    "default": 1,
                    "description": "Minimum number of sentences per chunk."
                },
                "min_chunk_size": {
                    "type": "integer",
                    "title": "Min Chunk Size",
                    "default": 2,
                    "description": "Minimum tokens per chunk."
                },
                "min_characters_per_sentence": {
                    "type": "integer",
                    "title": "Min Characters Per Sentence",
                    "default": 12,
                    "description": "Minimum number of characters per sentence."
                },
                "threshold_step": {
                    "type": "number",
                    "title": "Threshold Step",
                    "default": 0.01,
                    "description": "Step size used when automatically calculating the similarity threshold."
                },
                "delim": {
                    "anyOf": [
                        {
                            "type": "string"
                        },
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        }
                    ],
                    "title": "Delim",
                    "default": [
                        ".",
                        "!",
                        "?",
                        "\n"
                    ],
                    "description": "Delimiters to split sentences on."
                },
                "include_delim": {
                    "anyOf": [
                        {
                            "type": "string",
                            "enum": [
                                "prev",
                                "next"
                            ]
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "title": "Include Delim",
                    "default": "prev",
                    "description": "Include delimiters in the chunk text. If so, specify whether to include the previous or next delimiter."
                },
                "return_type": {
                    "type": "string",
                    "title": "Return Type",
                    "default": "chunks",
                    "enum": [
                        "texts",
                        "chunks"
                    ],
                    "description": "Return type for chunking. If 'chunks', returns a list of `SemanticChunk` objects. If 'texts', returns a list of strings."
                }
            },
            "additionalProperties": false
        },
        "SentenceChunkerREQ": {
            "title": "SentenceChunkerREQ",
            "description": "Data to pass to the Sentence Chunker.",
            "type": "object",
            "required": [
                "text"
            ],
            "properties": {
                "text": {
                    "anyOf": [
                        {
                            "type": "string"
                        },
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        }
                    ],
                    "title": "Text",
                    "description": "The input text or list of texts to be chunked."
                },
                "tokenizer_or_token_counter": {
                    "type": "string",
                    "title": "Tokenizer Or Token Counter",
                    "default": "gpt2",
                    "description": "Tokenizer or token counting function to use. Can be a string identifier or an instance."
                },
                "chunk_size": {
                    "type": "integer",
                    "title": "Chunk Size",
                    "default": 512,
                    "description": "Maximum number of tokens per chunk."
                },
                "chunk_overlap": {
                    "type": "integer",
                    "title": "Chunk Overlap",
                    "default": 0,
                    "description": "Number of overlapping tokens between chunks."
                },
                "min_sentences_per_chunk": {
                    "type": "integer",
                    "title": "Min Sentences Per Chunk",
                    "default": 1,
                    "description": "Minimum number of sentences to include in each chunk."
                },
                "min_characters_per_sentence": {
                    "type": "integer",
                    "title": "Min Characters Per Sentence",
                    "default": 1,
                    "description": "Minimum number of characters per sentence."
                },
                "approximate": {
                    "type": "boolean",
                    "title": "Approximate",
                    "default": true,
                    "description": "Use approximate token counting for faster processing (deprecated)."
                },
                "delim": {
                    "anyOf": [
                        {
                            "type": "string"
                        },
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        }
                    ],
                    "title": "Delim",
                    "default": [
                        "\n",
                        ".",
                        "!",
                        "?"
                    ],
                    "description": "Delimiters to split sentences on."
                },
                "include_delim": {
                    "anyOf": [
                        {
                            "type": "string",
                            "enum": [
                                "prev",
                                "next"
                            ]
                        },
                        {
                            "type": "null"
                        }
                    ],
                    "title": "Include Delim",
                    "default": "prev",
                    "description": "Include delimiters in the chunk text. If so, specify whether to include the previous or next delimiter."
                },
                "return_type": {
                    "type": "string",
                    "title": "Return Type",
                    "default": "chunks",
                    "enum": [
                        "texts",
                        "chunks"
                    ],
                    "description": "Whether to return chunks as text strings or as `SentenceChunk` objects."
                }
            },
            "additionalProperties": false
        },
        "TokenChunkerREQ": {
            "title": "TokenChunkerREQ",
            "description": "Data to pass to the Token Chunker.",
            "type": "object",
            "required": [
                "text"
            ],
            "properties": {
                "text": {
                    "anyOf": [
                        {
                            "type": "string"
                        },
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        }
                    ],
                    "title": "Text",
                    "description": "The input text or list of texts to be chunked."
                },
                "tokenizer": {
                    "type": "string",
                    "title": "Tokenizer",
                    "default": "gpt2",
                    "description": "Tokenizer to use. Can be a string identifier or a tokenizer instance"
                },
                "chunk_size": {
                    "type": "integer",
                    "title": "Chunk Size",
                    "default": 512,
                    "description": "Maximum number of tokens per chunk"
                },
                "chunk_overlap": {
                    "type": "integer",
                    "title": "Chunk Overlap",
                    "default": 0,
                    "description": "Number or percentage of overlapping tokens between chunks"
                },
                "return_type": {
                    "type": "string",
                    "title": "Return Type",
                    "default": "chunks",
                    "enum": [
                        "texts",
                        "chunks"
                    ],
                    "description": "Whether to return chunks as `Chunk` objects or plain text strings."
                }
            },
            "additionalProperties": false
        },
        "ValidationError": {
            "properties": {
                "loc": {
                    "items": {
                        "anyOf": [
                            {
                                "type": "string"
                            },
                            {
                                "type": "integer"
                            }
                        ]
                    },
                    "type": "array",
                    "title": "Location"
                },
                "msg": {
                    "type": "string",
                    "title": "Message"
                },
                "type": {
                    "type": "string",
                    "title": "Error Type"
                }
            },
            "type": "object",
            "title": "ValidationError"
        },
        "WordChunkerREQ": {
            "title": "WordChunkerREQ",
            "description": "Data to pass to the Word Chunker.",
            "type": "object",
            "required": [
                "text"
            ],
            "properties": {
                "text": {
                    "anyOf": [
                        {
                            "type": "string"
                        },
                        {
                            "items": {
                                "type": "string"
                            },
                            "type": "array"
                        }
                    ],
                    "title": "Text",
                    "description": "The input text or list of texts to be chunked."
                },
                "tokenizer_or_token_counter": {
                    "type": "string",
                    "title": "Tokenizer Or Token Counter",
                    "default": "gpt2"
                },
                "chunk_size": {
                    "type": "integer",
                    "title": "Chunk Size",
                    "default": 512
                },
                "chunk_overlap": {
                    "type": "integer",
                    "title": "Chunk Overlap",
                    "default": 0
                },
                "return_type": {
                    "type": "string",
                    "title": "Return Type",
                    "default": "chunks",
                    "enum": [
                        "texts",
                        "chunks"
                    ]
                }
            },
            "additionalProperties": false
        }
    }
}
